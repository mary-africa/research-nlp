{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "62bcb026-ef22-4f3b-ab45-fb6653082296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"../\" not in sys.path: sys.path.insert(0,\"../\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3812e208-2b25-465a-bba4-4349be507b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for the SED\n",
    "from marynlp.modules.source import save_model_from_google_bucket\n",
    "from marynlp.utils.storage import download, get_bucket\n",
    "\n",
    "\n",
    "# Download the morphmeme file\n",
    "bucket = get_bucket(\"../resources/mary_africa_credentials_key.json\", \"marynlp-private\")\n",
    "morph_template_file = save_model_from_google_bucket(\"models/sed_morpheme_template.txt\", bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9d112c8e-173d-499d-9234-71e6e109b804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/iam-kevin/.marynlp/store/models/sed_morpheme_template.txt')"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morph_template_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "8b5c048d-aa0c-4b21-94db-d72801346029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the words\n",
    "from marynlp import funcutils as f\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import List, Union\n",
    "import os\n",
    "import re\n",
    "\n",
    "def split_by_space(text: str) -> List[str]:\n",
    "    \"\"\"Split a text to word strings\n",
    "    \n",
    "    Example\n",
    "    \"Lorem ipsum\" -> [ 'Lorem', 'ipsum' ] \n",
    "    \"\"\"\n",
    "    return re.split(r\"\\s+\", text)\n",
    "\n",
    "def ignore_rules(text: str) -> bool:\n",
    "    return not (text.find(\"<text\") > -1 or text.find(\"</text>\") > -1)\n",
    "\n",
    "def should_be_longer_than_20(text: str) -> bool:\n",
    "    return len(text) > 20\n",
    "\n",
    "@f.filterBy(f.rules(ignore_rules, should_be_longer_than_20))\n",
    "def read_file(file_path) -> List[str]:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as rb:\n",
    "        return rb.readlines()\n",
    "\n",
    "@f.forEach(str, type_=set)\n",
    "@f.filterBy(lambda s: len(s.strip()) > 0)\n",
    "@f.flowBy(split_by_space)\n",
    "@f.forEach(lambda s: s.strip())\n",
    "def get_unique_words_from_shu_file(file_path: os.PathLike):\n",
    "    return tqdm(read_file(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "de1b9eb4-5b08-49e3-acb4-a7b08b46ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from typing import Iterable, Tuple\n",
    "\n",
    "from experimental.sed import MorphologyAnalyzer\n",
    "from marynlp import funcutils as f \n",
    "\n",
    "from collections.abc import Callable\n",
    "\n",
    "def break_word(word: str, analyzer: MorphologyAnalyzer) -> Tuple[str]:\n",
    "    return tuple([ su for su in analyzer.break_text([word])[word]])\n",
    "\n",
    "# Might not want to add this since it's pytorch specific?\n",
    "class MorphemeDataset(Dataset):\n",
    "    def __init__(self, word_iter: Iterable[str], break_word: Callable):\n",
    "        self.break_word = break_word\n",
    "        self.wml = list(word_iter)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        return self.break_word(self.wml[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.wml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "4ef631a2-202a-4845-98b4-e35ef031f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_morphemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "7f67cc8a-1670-46f1-ad0f-2fc8bcc0d9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 125/125 [00:00<00:00, 269003.59it/s]\n"
     ]
    }
   ],
   "source": [
    "from marynlp.text.data import Vocab, morph\n",
    "from marynlp.text import formatter as fmt\n",
    "from itertools import chain\n",
    "# from marynlp.utils import process as p\n",
    "\n",
    "unique_words = get_unique_words_from_shu_file(\"../resources/data/hcs-na-v2/new-mat/news/alasiri-2009.shu\")\n",
    "analyzer = MorphologyAnalyzer(morph_template_file)\n",
    "\n",
    "# start with remove punctuations\n",
    "clean_text = f.calls(fmt.remove_punctuations, fmt.white_space_cleaning, fmt.lowercase)\n",
    "\n",
    "@f.apply(f.calls(chain.from_iterable, set))\n",
    "def get_unique_morphemes(words: Iterable[str]):\n",
    "    breaker = f.calls(clean_text, f.partial(break_word, analyzer=analyzer))\n",
    "    for w in words:\n",
    "        try:\n",
    "            yield breaker(w)\n",
    "        except Exception as e:\n",
    "            print(\"Unable to break word: '%s'\" % w)\n",
    "            raise e\n",
    "\n",
    "            \n",
    "# unique_morphemes = get_unique_morphemes(unique_words)\n",
    "# morpheme_vocab = Vocab(unique_morphemes)\n",
    "# word_vocab = Vocab(map(clean_text, unique_words))\n",
    "# dataset = MorphemeDataset(unique_words, break_word=f.partial(break_word, analyzer=analyzer))\n",
    "# clean_text(\"sisi?,!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6bc7533a-fca6-4268-9d94-e1e8c85df340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('e', 'vin', 'jam', 'e', 's'), [101, -1, 217, 101, 434])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer_break_word = f.partial(break_word, analyzer=analyzer)\n",
    "\n",
    "m_l = analyzer_break_word(\"kevin james\")\n",
    "m_l, list(map(morph_encoder.encode, m_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "dff18372-28cf-4e2a-a450-a58edd5a2d3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 'vin', 'jam', 'e', 's')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  = f.partial(break_word, analyzer=analyzer)\n",
    "# get_unique_morphemes(\"kevin james\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9f7540a5-8e3c-4f69-8526-1fc0d53f4ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Vocab([alikuwa, anafundisha..., na], len=6), Vocab([ , 0..., zwa], len=569))"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: This must be updated the data\n",
    "#  in accordance to the data that is used to train the data\n",
    "\n",
    "word_vocab, morpheme_vocab # Vocab([ , 0..., zwa], len=569)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c8910cd9-43d9-4553-917f-cc0516fe8e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experimental.sed.nn import SEDLanguageModel\n",
    "from experimental.sed.modules.embeddings import SEDWordEmbeddings\n",
    "\n",
    "swe = SEDWordEmbeddings(\n",
    "    morpheme_vocab.size,\n",
    "    embedding_dim=100,\n",
    "    hidden_dim=32\n",
    ")\n",
    "\n",
    "def lm_pad_collate(batch):\n",
    "    x, x_len = [], []\n",
    "    \n",
    "    x_len = [m.shape[0] for m in batch]\n",
    "    max_len = max(x_len)\n",
    "    \n",
    "    x_batch_ = [np.pad(t, (0, max_len - t.shape[0])) if t.shape[0] < max_len else t for t in batch]\n",
    "    xx = torch.stack([torch.from_numpy(x).long() for x in x_batch_])\n",
    "\n",
    "    return xx, torch.as_tensor(x_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "ec098054-2507-4c5f-9b1e-ae75eb11dbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('ma', 'ma'), ('anak',), ('n', 'a'), ('ma', 'ma')], [('m', 'wali', 'mu'), ('ali', 'wa'), ('ana', 'fu', 'ndisha')]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 5, 11,  7],\n",
       "        [ 1, 10,  0],\n",
       "        [ 2,  4,  9],\n",
       "        [ 0,  0,  0]]),\n",
       " array([3, 2, 3, 0]),\n",
       " 3)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from marynlp.text.data import token\n",
    "from marynlp.text.processor import TokenEncoder\n",
    "\n",
    "from marynlp.text import formatter as fmt\n",
    "from itertools import chain\n",
    "\n",
    "from typing import List, Any\n",
    "\n",
    "\n",
    "def split_text_by_space(text: str) -> Tuple[str]:\n",
    "    return re.split(r'\\s+', fmt.white_space_cleaning(text)) \n",
    "\n",
    "\n",
    "@f.apply(list)\n",
    "def text_pad_sequence(word_sequence: Iterable[Any], padding_length: int, pad_marker: Any):\n",
    "    if len(word_sequence) >= padding_length:\n",
    "        return word_sequence\n",
    "    \n",
    "    return chain.from_iterable((word_sequence, [pad_marker] * (padding_length - len(word_sequence))))\n",
    "\n",
    "@f.apply(tuple)\n",
    "@f.apply(lambda o: zip(*o))\n",
    "def width_pad_sequence(var_sequences: Iterable[List[Any]], padding_length: int, pad_marker: Any):\n",
    "    for var_seq in var_sequences:\n",
    "        out = tuple(var_seq)\n",
    "        yield tuple(chain.from_iterable((out, [pad_marker] * (padding_length - len(var_seq))))), len(out)\n",
    "\n",
    "        \n",
    "PAD_TOKEN = token('<PAD>')\n",
    "\n",
    "\n",
    "morph_encoder = TokenEncoder(morpheme_vocab)\n",
    "word_to_morpheme = f.partial(break_word, analyzer=analyzer)\n",
    "encode_morpheme = f.apply(np.array)(f.forEach(morph_encoder.encode)(word_to_morpheme))\n",
    "\n",
    "\n",
    "# def pad_collateV2(batch):\n",
    "#     \"\"\"NOTE: This is the modified version from the package\"\"\"\n",
    "#     x, x_len = [], []\n",
    "    \n",
    "#     x_len = [m.shape[0] for m in batch]\n",
    "#     max_len = max(x_len)\n",
    "    \n",
    "#     x_batch_ = [np.pad(t, (0, max_len - t.shape[0])) if t.shape[0] < max_len else t for t in batch]\n",
    "#     xx = torch.stack([torch.from_numpy(x).long() for x in x_batch_])\n",
    "\n",
    "#     return xx, torch.as_tensor(x_len)\n",
    "\n",
    "\n",
    "\n",
    "# @f.apply(list)\n",
    "def morph_sentence_pad_collate(sentences: List[str], padding_idx: int = 0):\n",
    "    word_sequences = list(map(split_text_by_space, sentences))\n",
    "#     print(word_sequences)\n",
    "    \n",
    "    # padd each sequence\n",
    "    out_list = [list(map(word_to_morpheme, b)) for b in word_sequences]\n",
    "    print(out_list)\n",
    "\n",
    "    # get the longest character sequence in the entire batch\n",
    "    to_pad_morph_length = len(max(list(map(f.partial(max, key=len), out_list)), key=len))\n",
    "    to_pad_word_length = max(map(len, out_list))\n",
    "\n",
    "    morph_padd_function = f.partial(width_pad_sequence, padding_length=to_pad_morph_length, pad_marker=padding_idx)\n",
    "    \n",
    "#         print(\"m_idx_seq\", padd_function(m_idx_seq))\n",
    "    \n",
    "    # hold the number of words and morphme pair count\n",
    "    word_morphemes_count = []\n",
    "    words_tensors = []\n",
    "    words_c = []  # number of words in a sentence\n",
    "\n",
    "    for b in out_list:\n",
    "        word_list = [ list(map(morph_encoder.encode, b_)) for b_ in b ]\n",
    "#         print(word_list)\n",
    "        \n",
    "        padded_morph_sequence, lengths = morph_padd_function(word_list)\n",
    "        \n",
    "#         c, _ = morpheme_pad_collate(list(map(encode_morpheme, b)))\n",
    "#         word_count, longest_token_len = c.shape[0], c.shape[-1]\n",
    "\n",
    "        # grid padding\n",
    "        word_count = len(word_list)\n",
    "        padd_words_count = to_pad_word_length - word_count\n",
    "        out = (tuple([0] * to_pad_morph_length) for _ in range(padd_words_count))    \n",
    "        \n",
    "        words_tensors.append(np.array(list(chain(padded_morph_sequence, out))))\n",
    "#         word_morphemes_count.append(np.array(tuple(chain(lengths, [0] * padd_words_count))))\n",
    "        word_morphemes_count.append(\n",
    "            tuple(chain(\n",
    "                lengths, \n",
    "                [0] * padd_words_count # padding\n",
    "            )))\n",
    "    \n",
    "        words_c.append(word_count)\n",
    "\n",
    "    padded_length_tensors = np.array(word_morphemes_count)\n",
    "#         # get the remaining shape\n",
    "# #         print(c)\n",
    "#     print(out)\n",
    "                             \n",
    "    # padd the sentence objects\n",
    "#     padded_length_tensors = pad_sequence(word_morphemes_count, batch_first=True)\n",
    "\n",
    "    return np.array(words_tensors), np.array(padded_length_tensors), np.array(words_c)\n",
    "\n",
    "# def padded_input(pad_idx: int, padding_length: int):\n",
    "#     return np.array([pad_idx] * padding_length)\n",
    "\n",
    "\n",
    "# t, l = morpheme_pad_collate(list(MorphemeDataset([\"mama\", \"anakuja\"], encode_morpheme))); t\n",
    "\n",
    "# split sentence\n",
    "# lm = DataLoader()\n",
    "sentences = [\"mama anakuja na mama\", \"mwalimu alikuwa anafundisha\"]\n",
    "t, mcs, wc = morph_sentence_pad_collate(sentences); \n",
    "t.shape, mcs.shape, wc.shape\n",
    "\n",
    "# set_pad = \n",
    "# print(set_pad)\n",
    "t[1], mcs[1], wc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "31fbac53-bb22-495d-b413-c8a5238dec3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 4, 5],\n",
       "         [3, 2, 0]]),\n",
       " tensor([3, 2]))"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "morpheme_pad_collateV2([np.array([3, 4, 5]), np.array([3, 2])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e1d1c-2187-46dd-b961-5ec76d2c676e",
   "metadata": {},
   "source": [
    "### Showing Nelson how its done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "55700e98-9b36-4371-b94c-97df4a980bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alikuwa', 'mwalimu', 'anafundisha', 'na', 'anakuja', 'mama'}\n",
      "{'ndisha', 'ali', 'ana', 'a', 'wali', 'n', 'mu', 'm', 'anak', 'wa', 'ma', 'fu'}\n"
     ]
    }
   ],
   "source": [
    "from marynlp.text.processor import TokenEncoder\n",
    "from marynlp.text.data import Vocab\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "sentences = [\"mama anakuja na mama\", \"mwalimu alikuwa anafundisha\"]\n",
    "\n",
    "unique_words = set(list(chain.from_iterable(list(map(split_text_by_space, sentences)))))\n",
    "print(unique_words)\n",
    "unique_morphemes = get_unique_morphemes(unique_words)\n",
    "\n",
    "print(unique_morphemes)\n",
    "word_vocab = Vocab(unique_words)\n",
    "morpheme_vocab = Vocab(unique_morphemes)\n",
    "\n",
    "word_tokenizer = TokenEncoder(word_vocab)\n",
    "morpheme_tokenizer = TokenEncoder(morpheme_vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "1d893e78-7b0f-4522-bfff-90063e73ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the embeddings\n",
    "from experimental.sed.modules.embeddings import SEDWordEmbeddings\n",
    "swe = SEDWordEmbeddings(\n",
    "    morpheme_vocab.size,\n",
    "    embedding_dim=100,\n",
    "    hidden_dim=32\n",
    ")\n",
    "\n",
    "word_to_morpheme = f.partial(break_word, analyzer=analyzer)\n",
    "encode_morpheme = f.apply(np.array)(f.forEach(morph_encoder.encode)(word_to_morpheme))\n",
    "morpheme_dataset = MorphemeDataset(word_vocab.get_tokens(), break_word=encode_morpheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f38f9c30-1937-4d2b-9095-07928585c4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.85it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# for i in morpheme_dataset:\n",
    "#     print(i)\n",
    "embeddings = swe.fit(morpheme_dataset)\n",
    "embeddings = torch.tensor(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "40ee86ad-446f-48d2-8815-62e64253b055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 100]), Vocab([alikuwa, anafundisha..., na], len=6))"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape, word_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cc47fe1b-6538-433a-a88d-24a11852b69f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13440/4184664149.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;36m307\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m307\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         ]), \n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     ]\n\u001b[1;32m     14\u001b[0m )\n",
      "\u001b[0;32m~/Projects/ml/packages/mary/venv/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_sequence\u001b[0;34m(sequences, batch_first, padding_value)\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;31m# assuming trailing dimensions and type of all the Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;31m# in sequences are same and fetching those from sequences[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "pad_sequence(\n",
    "    [\n",
    "        torch.tensor([\n",
    "            [307, 307],\n",
    "            [ 40,   0],\n",
    "            [342,  11],\n",
    "            [307, 307]\n",
    "        ]), \n",
    "        torch.tensor([[2, 1, 2, 2]]),        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "291ebf56-e83a-451c-9ac4-563e0c289d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([3, 2, 5, 3]), tensor([4, 0, 1])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3, 2, 5, 3],\n",
       "        [4, 0, 1, 0]])"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the LM like a boss\n",
    "# TODO: padding_idx is 0 and first token index is 0: FIX THIS!!\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "word_encoded = [torch.tensor(list(map(word_tokenizer.encode, words))) for words in map(split_by_space, sentences)]; word_encoded\n",
    "# word_encoded = [np.array(list(map(word_tokenizer.encode, words))) for words in map(split_by_space, sentences)]; word_encoded\n",
    "\n",
    "print(word_encoded)\n",
    "# pad_sequence(word_encoded, batch_first=True)\n",
    "seq = pad_sequence(word_encoded, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9ce2b2f4-0a48-4b2f-b797-5a5a1bf037f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "a0264c8f-ab3f-46a6-bbee-dab9b3960d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 2, 5, 3],\n",
      "        [4, 0, 1, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1]),\n",
       " tensor([[0.1621, 0.1968, 0.1646, 0.1567, 0.1579, 0.1618],\n",
       "         [0.1711, 0.1890, 0.1596, 0.1528, 0.1631, 0.1644]],\n",
       "        grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_layer = SEDSequenceLayer(\n",
    "                word_vocab.size, \n",
    "                embedding_dim=embeddings.shape[-1], \n",
    "                comp_fn=None\n",
    "            )\n",
    "\n",
    "batched_emb_sequence = torch.matmul(torch.nn.functional.one_hot(seq).to(torch.float), embeddings)\n",
    "batched_emb_sequence.shape\n",
    "\n",
    "out = seq_layer.predict_proba(batched_emb_sequence)\n",
    "torch.argmax(out, dim=1), out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a3e8ce60-7ea6-40ae-9beb-1bc72f4933c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 4, 6]), torch.Size([1, 6, 100]))"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# one_hot = torch.nn.functional.one_hot(torch.tensor([3, 2, 5, 3])); one_hot\n",
    "one_hot = torch.nn.functional.one_hot(seq); \n",
    "one_hot.shape, embeddings.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "c04dc88a-0e86-4878-a2e5-1f299fa8bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit torch.matmul(torch.nn.functional.one_hot(seq).to(torch.float), embeddings).shape\n",
    "v2 = torch.matmul(torch.nn.functional.one_hot(seq).to(torch.float), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "c18c19aa-9402-467e-a3bd-0f1f16dd85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %timeit torch.tensor(np.array([np.array([embeddings[b].numpy() for b in g]) for g in seq])).shape\n",
    "v1 = torch.tensor(np.array([np.array([embeddings[b].numpy() for b in g]) for g in seq]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "50fef374-e347-45db-811b-e5e436f871c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True]],\n",
       "\n",
       "        [[True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True],\n",
       "         [True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True, True, True, True, True, True, True, True, True, True, True,\n",
       "          True]]])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3f34a9f2-980d-4480-a55c-d1a6279a2423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 2]) torch.Size([1, 2])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index_select(): Index is supposed to be a vector",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13440/2036640689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;36m342\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m11\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         [307, 307]]]),\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m )\n",
      "\u001b[0;32m~/Projects/ml/packages/mary/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13440/1969435653.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, input_len)\u001b[0m\n\u001b[1;32m    167\u001b[0m                ): \n\u001b[1;32m    168\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0memb_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswe_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0memb_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ml/packages/mary/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ml/packages/mary/experimental/sed/nn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_in, in_len, dim)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0memb_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_composition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ml/packages/mary/experimental/sed/nn.py\u001b[0m in \u001b[0;36mget_composition\u001b[0;34m(self, emb_in, in_len, dim)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0min_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0memb_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0mrnn_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_compose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/ml/packages/mary/venv/lib/python3.7/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0msorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index_select(): Index is supposed to be a vector"
     ]
    }
   ],
   "source": [
    "## Install Pytorch Lightning kama bado\n",
    "# !pip install pytorch-lightning\n",
    "import torch\n",
    "\n",
    "# from pytorch_lightning import Trainer\n",
    "# from experimental.sed.nn import SEDWordEmbeddingLayer\n",
    "\n",
    "# NOTE: I think When training and changing the model to training mode (`.train()`),\n",
    "# all the models weights are unfrozen (so it )\n",
    "sed_lang_model = SEDLanguageModel(\n",
    "                    # This is important to get the same model shape\n",
    "                    swe.swe_layer,\n",
    "                    word_count=word_vocab.size\n",
    "                 )\n",
    "\n",
    "\n",
    "sed_lang_model(\n",
    "    torch.tensor([[[307, 307],\n",
    "        [ 40,   0],\n",
    "        [342,  11],\n",
    "        [307, 307]]]),\n",
    "    torch.tensor([[4, 2]])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a9ec7-31da-40bb-b6c1-9d499b80262c",
   "metadata": {},
   "source": [
    "## Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c2eb1-8599-47d6-9112-a72a3f9ae73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer():\n",
    "    def __init__(self):\n",
    "        \"\"\"Setting the configuration for training the model properly\"\"\"\n",
    "        pass\n",
    "    \n",
    "    @classmethod\n",
    "    def result_from_checkpoint(cls, model):\n",
    "        \"\"\"Reset from the checking\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def train(self, model, train_dataloader, val_dataloader, test_dataloader):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Pipeline(object):\n",
    "    def __init__(self, train_data, test_data, model, save_path=None, resume_from_checkpoint=False, model_weights=None):\n",
    "        \n",
    "        self.model = model            \n",
    "        self.resume_train = resume_from_checkpoint\n",
    "        self.model_weights = model_weights\n",
    "\n",
    "        if self.resume_train:\n",
    "            assert model_weights is not None, \"specify model weights save location\"\n",
    "            self.load_model_checkpoint(self.model_weights)\n",
    "\n",
    "        if ModelsConfig.lang_mod:\n",
    "            DataConfig.dataloader_params['collate_fn'] = lambda x: lm_pad_collate(\n",
    "                x, \n",
    "                lang_mod=True,\n",
    "                frozen_embeddings=EmbeddingsConfig.freeze_embeddings,\n",
    "                )\n",
    "        \n",
    "        self.train_loader = DataLoader(train_data, **DataConfig.dataloader_params)\n",
    "        self.test_loader = DataLoader(test_data, **DataConfig.dataloader_params)\n",
    "\n",
    "        self.criterion = F.cross_entropy\n",
    "        self.optimizer = optim.AdamW(self.model.parameters(), lr=ModelsConfig.learning_rate)\n",
    "        \n",
    "        self.iter_meter = IterMeter()\n",
    "        self.save_path = save_path\n",
    "        self.model_checkpoints = []\n",
    "\n",
    "    def train(self, epoch, verbose):\n",
    "        self.model.train()\n",
    "        \n",
    "        start_time = time()\n",
    "        data_len = len(self.train_loader.dataset)\n",
    "\n",
    "        for batch_idx, _data in enumerate(self.train_loader):\n",
    "            x, x_len, y = _data \n",
    "\n",
    "            y = [y_.to(ModelsConfig.device) for y_ in [y]]\n",
    "            y = [y_.reshape(y_.shape[0],) for y_ in y]\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            output = self.model((x, x_len))\n",
    "            loss = self.criterion(output, y[0])\n",
    "            loss.backward()\n",
    "\n",
    "            self.optimizer.step()\n",
    "            if batch_idx % verbose == 0 or batch_idx == data_len:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tPerplexity: {:5.2f}\\telapsed: {:.2f} mins'.format(\n",
    "                    epoch, batch_idx * len(x), data_len,\n",
    "                    100. * batch_idx / len(self.train_loader), loss.item(), np.exp(loss.item()), (time()-start_time)/60))#, loss2.item()))\\tap_Loss: {:.6f}\n",
    "                \n",
    "    def test(self, epoch):\n",
    "        print('\\nevaluating…')\n",
    "        self.model.eval()\n",
    "        test_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for I, _data in enumerate(self.test_loader):\n",
    "                x, x_len, y = _data  \n",
    "\n",
    "                y = [y_.to(ModelsConfig.device) for y_ in [y]]\n",
    "                y = [y_.reshape(y_.shape[0],) for y_ in y]\n",
    "\n",
    "                output = self.model((x, x_len))\n",
    "                loss = torch.sum(torch.stack([self.criterion(out, y) for out,y in zip([output], y)]))\n",
    "                test_loss += loss.item() / len(self.test_loader)\n",
    "\n",
    "        print('Test set: Average loss: {:.4f} | Perplexity: {:8.2f}\\n'.format(test_loss, np.exp(test_loss)))\n",
    "\n",
    "        return round(test_loss, 4), self.model.state_dict()\n",
    "        \n",
    "    def train_model(self, early_stop=3, verbose=10):\n",
    "        \n",
    "        accum_loss = torch.tensor(float('inf')) if not self.resume_train else torch.tensor(float(re.findall(\"\\d+\\.\\d+\", self.model_weights)[0]))\n",
    "        stop_eps = 0 \n",
    "        try:\n",
    "            for epoch in range(1, ModelsConfig.EPOCHS + 1):\n",
    "                self.train(epoch, verbose)             \n",
    "                test_loss, w8 = self.test(epoch)\n",
    "                \n",
    "                if test_loss < accum_loss:\n",
    "                    self.model_checkpoints.append((w8, test_loss))\n",
    "                    accum_loss = test_loss\n",
    "                    stop_eps = 0\n",
    "                else:\n",
    "                    stop_eps += 1\n",
    "\n",
    "                if stop_eps >= early_stop:\n",
    "                    self.save_model_checkpoint()\n",
    "                    break\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            self.save_model_checkpoint() if self.model_checkpoints else print(\"first epoch not completed, model checkpoint will not be saved\")\n",
    "\n",
    "    def save_model_checkpoint(self):\n",
    "        best_model, accum_loss = self.model_checkpoints[-1]\n",
    "\n",
    "        if self.save_path is not None and not ModelsConfig.lang_mod:\n",
    "            torch.save(best_model, Path(self.save_path).joinpath(f'{accum_loss}_SAM.pth'))\n",
    "        \n",
    "        if self.save_path is not None and ModelsConfig.lang_mod:\n",
    "            torch.save(best_model, Path(self.save_path).joinpath(f'{accum_loss}_lm.pth'))\n",
    "\n",
    "    def load_model_checkpoint(self, model_weights):\n",
    "        self.model.load_state_dict(torch.load(Path(model_weights)))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5eef2-e862-45bb-8c99-182955c1e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training pipeline\n",
    "from \n",
    "\n",
    "swl = SEDLanguageModel(swe.swe_layer, word_count=word_vocab.size)\n",
    "swl.train()\n",
    "        \n",
    "start_time = time()\n",
    "data_len = len(self.train_loader.dataset)\n",
    "\n",
    "for batch_idx, _data in enumerate(self.train_loader):\n",
    "    x, x_len, y = _data \n",
    "\n",
    "    y = [y_.to(ModelsConfig.device) for y_ in [y]]\n",
    "    y = [y_.reshape(y_.shape[0],) for y_ in y]\n",
    "\n",
    "    self.optimizer.zero_grad()\n",
    "\n",
    "    output = self.model((x, x_len))\n",
    "    loss = self.criterion(output, y[0])\n",
    "    loss.backward()\n",
    "\n",
    "    self.optimizer.step()\n",
    "    if batch_idx % verbose == 0 or batch_idx == data_len:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tPerplexity: {:5.2f}\\telapsed: {:.2f} mins'.format(\n",
    "            epoch, batch_idx * len(x), data_len,\n",
    "            100. * batch_idx / len(self.train_loader), loss.item(), np.exp(loss.item()), (time()-start_time)/60))#, loss2.item()))\\tap_Loss: {:.6f}\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
